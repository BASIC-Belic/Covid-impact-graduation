{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /home/jovyan/.local/lib/python3.6/site-packages (1.4.3)\r\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c793c2f0539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_future_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://educationdata.urban.org/api/v1/school-districts/ccd/finance/2012/\n",
      "Fetching data from https://educationdata.urban.org/api/v1/school-districts/ccd/finance/2013/\n",
      "Fetching data from https://educationdata.urban.org/api/v1/school-districts/ccd/finance/2014/\n",
      "Fetching data from https://educationdata.urban.org/api/v1/school-districts/ccd/finance/2015/\n",
      "Fetching data from https://educationdata.urban.org/api/v1/school-districts/ccd/finance/2016/\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "!{sys.executable} -m pip install --user nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from json import loads\n",
    "from functools import reduce\n",
    "\n",
    "valid_years = [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\"]\n",
    "\n",
    "'''\n",
    "Federal Information Processing Standards state code\n",
    "'''\n",
    "fips_mapping = { 1:\"Alabama\", 2:\"Alaska\",  3:\"American Samoa\", 4:\"Arizona\", 5:\"Arkansas\", 6:\"California\", \n",
    "                7:\"Canal Zone\", 8:\"Colorado\", 9:\"Connecticut\", 10:\"Delaware\", 11:\"District of Columbia\", 12:\"Florida\", \n",
    "                13:\"Georgia\", 14:\"Guam\", 15:\"Hawaii\", 16:\"Idaho\", 17:\"Illinois\", 18:\"Indiana\", 19:\"Iowa\", 20:\"Kansas\",\n",
    "                21:\"Kentucky\", 22:\"Louisiana\", 23:\"Maine\", 24:\"Maryland\", 25:\"Massachusetts\", 26:\"Michigan\", \n",
    "                27:\"Minnesota\", 28:\"Mississippi\", 29:\"Missouri\", 30:\"Montana\", 31:\"Nebraska\", 32:\"Nevada\", \n",
    "                33:\"New Hampshire\", 34:\"New Jersey\", 35:\"New Mexico\", 36:\"New York\", 37:\"North Carolina\", \n",
    "                38:\"North Dakota\", 39:\"Ohio\", 40:\"Oklahoma\", 41:\"Oregon\", 42:\"Pennsylvania\", 43:\"Puerto Rico\", \n",
    "                44:\"Rhode Island\", 45:\"South Carolina\", 46:\"South Dakota\", 47:\"Tennessee\", 48:\"Texas\", 49:\"Utah\", \n",
    "                50:\"Vermont\", 51:\"Virginia\", 52:\"Virgin Islands of the US\", 53:\"Washington\", 54:\"West Virginia\", \n",
    "                55:\"Wisconsin\", 56:\"Wyoming\", 58:\"Department of Defense Dependent Schools (overseas)\", \n",
    "                59:\"Bureau of Indian Education\", 60:\"American Samoa\", 61:\"Department of Defense Dependent Schools (domestic)\", \n",
    "                63:\"Department of Defense Education Activity\", 64:\"Federated States of Micronesia\", \n",
    "                65:\"Mariana Islands waters (including Guam)\", 66:\"Guam\", 67:\"Johnston Atoll\", 68:\"Marshall Islands\", \n",
    "                69:\"Northern Mariana Islands\", 70:\"Palau\", 71:\"Midway Islands\", 72:\"Puerto Rico\", \n",
    "                74:\"US Minor Outlying Islands\", 75:\"Atlantic coast from North Carolina to Florida, and the coasts of Puerto Rico and Virgin Islands\", \n",
    "                76:\"Navassa Island\", 78:\"Virgin Islands of the US\", 79:\"Wake Island\", 81:\"Baker Island\", 84:\"Howland Island\", \n",
    "                86:\"Jarvis Island\", 89:\"Kingman Reef\", 95:\"Palmyra Atoll\", -1:\"Missing/not reported\", -2:\"Not applicable\", -3:\"Suppressed data\"\n",
    "               }\n",
    "'''\n",
    "Method accepts array of urls\n",
    "Returns concatenated dataframe with data from urls\n",
    "''' \n",
    "async def get_data_frame(url):  \n",
    "#     dfs = []   \n",
    "#     for url in urls:\n",
    "#         count = 0\n",
    "    while url:\n",
    "#Use the following while loop so I can fetch less urls before making this method async:\n",
    "#         while url and count < 4:\n",
    "        print(\"Fetching data from\", url)\n",
    "        response = urlopen(url)\n",
    "        data = loads(response.read())\n",
    "        dfs.append(pd.DataFrame.from_dict(data[\"results\"]))\n",
    "        url = data[\"next\"]\n",
    "        print(\"Next url:\", url)\n",
    "#         count+=1\n",
    "    return pd.concat(dfs, ignore_index=True, sort=True)\n",
    "\n",
    "async def run_future_tasks(urls):\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    tasks = []  \n",
    "    for url in urls:\n",
    "        tasks.append(asyncio.ensure_future(get_data_frame(url)))\n",
    "    for task in tasks: \n",
    "        await task\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "#TODO: delete urls & refactor this code for use in the other code blocks below\n",
    "urls = [\"https://educationdata.urban.org/api/v1/school-districts/ccd/finance/{}/\".format(yr) for yr in valid_years]\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(run_future_tasks(urls))\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(\"Tasks executed in %0.2f seconds.\" % (elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Unforunately, API does not have years past 2016.\n",
    "Following loads district level financial data w/ \"leaid\": \n",
    "Local education agency identification number (NCES) as a common identifier.\n",
    "'''\n",
    "finance_urls = [\"https://educationdata.urban.org/api/v1/school-districts/ccd/finance/{}/\".format(yr) for yr in valid_years]\n",
    "finance_df = get_data_frames(finance_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Unforunately, API does not have years past 2016.\n",
    "Following loads district level student poverty data w/ \"leaid\": \n",
    "Local education agency identification number (NCES) as a common identifier.\n",
    "'''\n",
    "\n",
    "poverty_urls = [\"https://educationdata.urban.org/api/v1/school-districts/saipe/{}/\".format(yr) for yr in valid_years]\n",
    "poverty_df = get_data_frames(finance_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Unforunately, API does not have years past 2016.\n",
    "And states: ['AL' 'AK' 'AZ' 'IL' 'CA' 'MI' 'MD' 'MN' 'TX' 'AR' 'NV']\n",
    "Following loads geographic data w/ \"leaid\": \n",
    "Local education agency identification number (NCES) as a common identifier.\n",
    "'''\n",
    "\n",
    "geographic_urls = [\"https://educationdata.urban.org/api/v1/school-districts/ccd/directory/{}/\".format(yr) for yr in valid_years]\n",
    "geographic_df = get_data_frames(finance_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(finance_df, geographic_df, on=[\"leaid\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate total revenue 'rev_total' (fed, state, local) for all states.\n",
    "'''\n",
    "df.rename(columns={'fips_x':'State'}, inplace = True)\n",
    "df.rename(columns={'year_y':'Year'}, inplace = True)\n",
    "\n",
    "grouped_series = df.groupby(['State', 'Year'])['rev_total_x'].sum().reset_index(name='Total Revenue')\n",
    "\n",
    "# num_years = len(grouped_series['Year'].unique())\n",
    "state_codes = grouped_series['State'].unique()\n",
    "years = grouped_series['Year'].unique()\n",
    "\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(grouped_series['State'].unique()))]\n",
    "\n",
    "'''\n",
    "Generate sample graphs using colors and random ints\n",
    "'''\n",
    "\n",
    "# Sample Graph 1\n",
    "for i in range(len(state_codes)):\n",
    "    plt.scatter(random.randint(0, 10), random.randint(0,10), c=colors[i], s=200)\n",
    "\n",
    "plt.title('Sample Graph 1')\n",
    "plt.show()\n",
    "    \n",
    "# Sample Graph 2  \n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(state_codes)):\n",
    "    x, y = np.random.rand(2, len(years))\n",
    "    scale = 200.0 * np.random.rand(len(years))\n",
    "    ax.scatter(x, y, c=colors[i], s=scale, label=state_codes[i],\n",
    "               alpha=1, edgecolors='none')\n",
    "\n",
    "ax.legend(title='States')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title('Sample Graph 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot the total revenue 'rev_total' (fed, state, local) for all states by year\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(len(state_codes)):\n",
    "    curr_state_code = state_codes[i]\n",
    "    curr_total_revenues = grouped_series.loc[grouped_series['State'] == curr_state_code]['Total Revenue']/1000000\n",
    "    \n",
    "    if(len(curr_total_revenues) != len(years)):\n",
    "        print(\"Missing some data for state: \", fips_mapping[curr_state_code], \" . Skipping...\")\n",
    "    else:\n",
    "        x , y =  years, curr_total_revenues\n",
    "        ax.scatter(x, y, c=colors[i], label=fips_mapping[curr_state_code], alpha=1, edgecolors='none')\n",
    "\n",
    "ax.legend(title='States', bbox_to_anchor=(1.0, 1.0))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title('Revue by State Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot the total revenue 'rev_total' (fed, state, local) for all states by year starting at origin\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "min_revenue = float('inf')\n",
    "max_revenue = -1 * float('inf')\n",
    "\n",
    "for i in range(len(state_codes)):\n",
    "    curr_state_code = state_codes[i]\n",
    "    curr_total_revenues = grouped_series.loc[grouped_series['State']== curr_state_code]['Total Revenue']\n",
    "    \n",
    "    curr_min = np.min(curr_total_revenues)\n",
    "    revenue_normalizer = lambda t: (t - curr_min)/1000000\n",
    "    normalized_revenues = np.array([revenue_normalizer(x) for x in curr_total_revenues])\n",
    "    \n",
    "    if(len(curr_total_revenues) != len(years)):\n",
    "        print(\"Missing some data for state: \", fips_mapping[curr_state_code], \" . Skipping...\")\n",
    "    else:\n",
    "        x , y =  years, normalized_revenues\n",
    "        plt.scatter(x, y, c=colors[i], label=fips_mapping[curr_state_code], alpha=1, edgecolors='none')\n",
    "        plt.plot(x, y)\n",
    "\n",
    "ax.legend(title='States', bbox_to_anchor=(1, 1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title('Revenue By State Over Time Normalised from $0')\n",
    "plt.xlabel('Years', fontsize=12)\n",
    "plt.ylabel('Normalized Total Revenue($M)', fontsize=12)\n",
    "plt.xticks(np.arange(np.min(years), np.max(years)+1, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
